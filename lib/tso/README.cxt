[{h1}TSO: tab separated objects]

[" [*Note:] The initial Lua implementation of TSO is complete and is minimally
   tested. The spec may change at any time, though I don't expect major changes.

   Major usage has not yet been done. Use at your own risk and expect some
   bugs.
]

TSO is a concise and expressive data serialization format. If JSON and CSV had
a baby then their prodigal child would be something like TSO.

Unlike CSV, TSO supports nested records and has an actual spec. Unlike JSON,
TSO is concise and large lists of records can be made very readable.

Features: [+
* Serialize nested arbitrary data
* Human readable and writeable. Favors readability over writeability.
* Supported types: none, boolean, number, string, table (list/map hybrid)
* Single and "row" table specifications supported, similar to CSV headers
* Design supports (future) fast serialization and deserialization implementation
]

[" Did you know that CSV is both faster to parse and almost as compressed as
   protobufs? [<@compare>I was surprised too].]

[{!:href=https://blog.mbedded.ninja/programming/serialization-formats/a-comparison-of-serialization-formats/}compare]

[!--------------------------------]
[{:h2}Starting Example]
[! Recommendation for text editors: increase your tab size
vim	:set ts=12
]

TSO represents the items in a table as a series of tab separated values.
Similar to CSV, newlines start a new table (aka "row"). The first character
specifies the type, all map keys are strings.

[##
-- JSON: [
--   [1, 2, 3],
--   {"name": "John", "birthday": "1999-10-31"}
-- ]

-- TSO:
1	2	3
.name	"John	.birthday	"1999-10-31
]##

[$!] specifies a header spec and [$#] uses it The header extracts the keys for
the first columns specified:

[##
-- JSON: [
--   {"id": 1, "name": "John",   "birthday": "1999-10-31"},
--   {"id": 2, "name": "Maxine", "birthday": "1998-12-25"}
-- ]

-- TSO
!person	"id	"name	"birthday
#person
1	"John	1999-10-31
2	"Maxine	1998-12-25
]##

Unlike CSV, TSO supports nested data with named headers:

[##
-- JSON: [
--   users = [
--     {"id": 1, "name": "John",   "birthday": "1999-10-31"},
--     {"id", 2, "name": "Maxine", "birthday": "1998-12-25"}
--   ],
--   accounts = [
--     {"userId": 1, "ammount": 1000, "kind": "savings"},
--     {"userId": 1, "ammount": 100,  "kind": "checking"},
--     {"userId": 2, "ammount": 120,  "kind": "checking", "notes": [
--       {"date": "2020-01-03", "text": "wants investment advice"},
--       {"date": "2019-11-05,  "text": "yelled at clerk"}
--     ]}
--   ]
-- ]

-- '!' creates spec definitions, which are used for headers (row specs) 
-- and table specs.
!note	"date	"text
!user	"name	"birthday
!account	"userId	"ammount	"kind

.users	{
  #user
  John	1999-10-31
  Maxine	1998-12-25
}

.accounts	{
  #account
  1	1000	"savings
  1	100	"checking
  2	120	"checking	.notes	{
    #note
    "2020-01-03	"wants investment advice
    "2019-11-05	"yelled at clerk
  }
}
]##

Other quality of life features:
[##
-- line comment, can appear at start of line or after any tab
-- @ defines global attributes. Some of them (ibase, fbase) affect
-- parsing. All attributes can be read by the deserializer
@name	"my.data.name	-- set the doc name
@doc
+"This is a multiline string
 'documenting the purpose of this data
 'and how it should be used
@ibase	10	-- change the integer base (10 is default)
]##

[{:h2}Types]
The type of an item is determined by the first non-whitespace character after
the newline or tab. All values except tables end with a tab [$\t] character,
the behavior of tables is documented below.

[{table}
+ character | description
+ [$n] | none.

  lua [$ds.none], python [$None], C/java/etc [$null]

+ [$t] [$f] | boolean true and false
+ [$$] or [$(-)0-9] | integer parsed using (base = attr [$ibase])
+ [$^] | floating point parsed using (base = attr [$fbase])
+ [$"] | string (binary data)

  Examples
  [##
  -- 3, "a string", 42
  3, "a string	42	
  
  "a multiline string\t <-- that's a tab.
  'This is on the next line. The next line is empty:
  '	3 -- after the string there is a 3 integer
  ]##

  A tab [$\t] or newline [$\n] end the string. To continue the string
  after a newline use a [$'] as the first non-whitespace character
  following the newline.

  To encode a tab use [$"\t"]. To encode a [$\] character use [$"\\"] or
  simply use [$'\'] followed by
  neither [$'\'] or [$'t'].


+ [${] | nested table until [$}].
+ [$.] | key, the following item is a value

  Only string (binary) keys are supported. If you need other kinds of
  keys then encode whatever type you want in the string

+ [$\n] | row (inner table) delimiter

  Conceptually this ends the current row (non bracketed [${}] table) and
  starts a new row

+ [$+] | row continuation

  This continues the previous row and is commonly used for multiple key/values
  [##
  .key1	"value1
  +.key2	"value2
  ]##

+ [$*] | bracket table continutation (very rare)

  This is necessary to represent a table of the form [$rows={{1,2},{3,4}, 5, 6}]
  (note that 5 and 6 are NOT part of a row)
  [##
  .rows	{
    1	2	-- row 1
    3	4	-- row 2
    *5	6	-- note: NOT a row, individual values
  }
  ]##

  It is available mostly so that arbitrary data can be represented.

+ [$!] | spec definition: define a header/table spec

  This allows TSO to be highly concise both for rows of data (using [$#header])
  and single tables (using [$:single]) (unlike JSON which requires repeating
  the schema).

  [##
  -- spec named "person" with fields "name" and "age"
  !person	"name	"age
  ]##

  > Note: spec definitions must come before any data

  TSO does not [/require] that the specs are part of the document (they can be
  provided externally in the library's API). However, it is recommended for
  MOST cases as it makes the document self-documenting as well as ensuring that
  the specs don't drift. If your application has some other rock-solid
  mechanism of ensuring the types don't drift (i.e. a version attribute you
  ensure) then you may ommit spec definitions.


+ [$#] | header spec: specify the spec for rows

  [##
  #person	-- previously defined spec
  "Rob Clark	33
  "Jane Gelerard	27
  ]##

+ [$:] | single spec: specify the spec for a single table.

  [##
  -- JSON: [0, {"name": "Joe", "age": 22}, 3]
  0	{:person	"Joe	22	}	3
  ]##

  This is kind of like (and can be used for) "type tagging" and is useful when
  you have data with embedded types.
]

[*A note on Tables]

Tables can contain both indexed values (like a traditional list) as well
as string-keyed values (like a map). This is more similar to a
serialization format like XML which contain both attributes and data.

[" [*Recommendation]: this is the native behavior of Lua tables. In
   python or javascript you would want to key off the list vs index
   depending on the type of the key. In compiled languages, just offer
   different [$get] methods.
]

[" [*Note]: Because TSO only allows string keys there is no conflict between languages
   languages with different starting indexes.
]

[{:h2}Extensions]
An astute observer may notice that TSO defines no specific object model: no way
for a Pyton/Lua/Java/etc user to convert an object from a defined language type
("class") into their given language's type.

This is not defined directly. However, two features make such an extension
relatively straightforward for a library: [+

* [$attrs] allow specifying a type mapping with field spec ids:
  [##
  @types	{
    #"spec	"type
    0	"graphics.Point
    1	"graphics.Line
    2	"graphics.Quad
  }
  ]##
* header/field specs can now be used as needed for encoding the data
  [##
  :0	"x	"y	-- Point: 2 coordinates
  :1	"start	"end	-- Line: 2 Points
  :2	"left	"right	-- Quad: 2 Lines
  #2	-- each row is a Quad
  {:1	{:0	10	10}	{:0	10	20}}
  +{:1	{:0	20	10}	{:0	20	20}}
  -- ... other quads
  ]##
]

In the above imagination, the "spec" refers to the TSO header/field spec and the "type"
refers to some library name. A few things to note: [+
* Assuming a reasonably large amount of data, the type specification takes up very little room:
  two bytes per object on average. However, the header encoding makes it
  relatively easy for even a human to read the document (and especially easy
  for a program to do so).
* In the example above, conciceness was chosen instead of human
  read/writeability. The library could choose to instead use more human
  readable spec names (i.e. use "Point" instead of "0")
]

When the deserializer library reads the above document, they will have access
not only the the [$@types] but also to the [$#field] specs. They can use
this metadata for multiple purposes, including comparing against their library
(to check for changes to the types) and even to support backwards-compatibility
(i.e. adding fields or changing field types).

They are also free to create an alternative type schema or include other attributes
which specify versioning information/etc. TSO supports these features without specifying
them.

[{:h2 name=with-luck}Integration with Luck]
TSO will be integrated with [@luck]. Specifically the [$@name] attribute will be used
as when resolving luck dependency names and luck will automatically deserialize
tso files.

Like luck files, the default name is the file name without the [$.tso] extension.

[{!:href=https://github.com/civboot/civlua/tree/main/luck}luck]

